# Multi-Agent Analytics Gateway (MAAG)
A Production-Ready Agentic Analytics Engine  
Transforming **Natural Language â†’ SQL â†’ Executable Insights** using  
**RAG, Multi-Agent Workflow, DuckDB, FAISS, and LLM Orchestration**

---

## ğŸ§  1. Overview

The **Multi-Agent Analytics Gateway (MAAG)** is a modular, scalable, agent-driven analytics framework designed to convert **natural language questions into validated SQL queries**, execute them against a **DuckDB data lake**, and return **concise, accurate insights**.

MAAG combines:

- **Multi-Agent System (MAS)**
- **Retrieval-Augmented Generation (RAG)**
- **Metadata Vector Indexing (FAISS)**
- **DuckDB Query Engine**
- **LLM Prompt Orchestration**
- **Token Safety Layer**
- **FastAPI Backend**
- **Gradio UI**

MAAG is engineered to be:

- ğŸ’¡ **Explainable** (SQL shown to user)  
- ğŸ§± **Modular** (each agent is replaceable)  
- ğŸš€ **Scalable** (works on 1MB â†’ 100GB parquet datasets)  
- ğŸ” **Safe** (token guards + row limits)  
- ğŸ›  **Deployable** (Docker, EC2-ready)

---

## ğŸ“¦ 2. Key Features

### âœ”ï¸ Multi-Agent Pipeline
- **Retrieval Agent** â†’ build contextual understanding using FAISS metadata  
- **NLâ†’SQL Agent** â†’ translate natural language into SQL  
- **SQL Validator Agent** â†’ correct structure, fix missing table/columns  
- **SQL Executor** â†’ safe execution with row limits  
- **Response/Summarization Agent** â†’ final human-readable insight

---

### âœ”ï¸ Metadata-Based RAG
Instead of embedding full dataset (too large), we embed **table schemas, column names, and column descriptions** â€” lightweight and scalable.

---

### âœ”ï¸ LLM Provider Switching
Swap between:
- **OpenAI**
- **Gemini**
- **Ollama (local models)**  
via `.env` or config settings.

---

### âœ”ï¸ DuckDB Execution Layer
Reads **Parquet** directly without loading entire dataset into memory.

Perfect for:
- 10MB CSV  
- 50GB Parquet  
- 100GB+ partitioned data lakes  

---

### âœ”ï¸ Token Safety Guard
Prevents runaway token usage:
- Blocks prompts that exceed estimated token cost  
- Stops queries returning huge row sets  
- Toggleable from config

---

### âœ”ï¸ FastAPI Backend (Production Ready)
Provides:
- `/api/ask` â†’ NL query endpoint  
- `/api/sql` â†’ raw SQL endpoint  
- `/api/health` â†’ system diagnostics  

---

### âœ”ï¸ Gradio UI (Simple + Minimal)
Frontend for interactive querying.

---

### âœ”ï¸ CLI Ingestion & Pipeline Runner
`main.py` serves as ingestion and FAISS index builder.

---

## ğŸ“ 3. Project Structure

```
.
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ ask.py
â”‚   â”‚   â”œâ”€â”€ sql.py
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ ask_routes.py
â”‚   â”‚   â”œâ”€â”€ sql_routes.py
â”‚   â”‚   â”œâ”€â”€ health_routes.py
â”‚   â”œâ”€â”€ server.py
â”‚
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ controller.py
â”‚   â”œâ”€â”€ nl_to_sql_agent.py
â”‚   â”œâ”€â”€ retrieval_agent.py
â”‚   â”œâ”€â”€ validation_agent.py
â”‚   â”œâ”€â”€ summarization_agent.py
â”‚   â”œâ”€â”€ response_agent.py
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ llm.py
â”‚   â”œâ”€â”€ rag.py
â”‚   â”œâ”€â”€ sql_executor.py
â”‚   â”œâ”€â”€ utils.py
â”‚
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ loader.py
â”‚   â”œâ”€â”€ converter.py
â”‚   â”œâ”€â”€ cleaner.py
â”‚
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ duckdb_client.py
â”‚   â”œâ”€â”€ index_builder.py
â”‚   â”œâ”€â”€ metadata_store.py
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ app.py (Gradio UI)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ retail.duckdb
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ test_rag.py
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ ingest_all.py
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â”œâ”€â”€ architecture.md
```

---

## âš™ï¸ 4. Installation & Setup

### **1. Clone Repo**
```
mkdir MAAG
cd MAAG
git clone https://github.com/SourabhGuptaGit/Multi-Agent-Analytics-Gateway.git .
```

### **2. Create environment**
```
uv venv
.\.venv\Scripts\activate  # Windows
source ./.venv/bin/activate  # Linux/Mac
```

### **3. Install dependencies**
```
uv pip install -r requirements.txt
```

### **4. Create `.env`**
```
OPENAI_API_KEY=sk-xxxx
GEMINI_API_KEY=xxxxx
LLM_PROVIDER=openai
LOG_LEVEL=INFO
```

---

## ğŸ“¥ 5. Ingestion Pipeline (CSV â†’ Parquet â†’ DuckDB â†’ FAISS Metadata)

### **Add CSV files to:**
```
data/raw/
```

### **Run ingestion**
```
python main.py ingest
```

### **Rebuild FAISS index**
```
python main.py rebuild
```

This will:
- Convert CSV â†’ Parquet  
- Register tables in DuckDB  
- Extract metadata JSON  
- Build FAISS index for metadata search  

---

## ğŸš€ 6. Running the Backend API

```
uvicorn api.server:app --reload --port 8000
```

Open:
```
http://localhost:8000/docs
```

---

## ğŸ’¬ 7. Running the UI

```
python ui/app.py
```

Gradio will launch at:
```
http://localhost:7860
```

---

## ğŸ”„ 8. Complete End-to-End Flow

### Step-by-step:
1. User enters a natural language question  
2. Retrieval agent pulls metadata using FAISS  
3. NLâ†’SQL agent generates SQL  
4. SQL Validator agent validates / auto-fixes  
5. SQL Executor runs on DuckDB  
6. Response Agent summarizes result in human language  
7. UI/API returns SQL + answer + table  

---

## ğŸ“ˆ 9. Scaling Beyond 100GB (Design Notes)

This system is scalable because:

### âœ”ï¸ DuckDB reads Parquet **lazily**
- No need to load entire dataset  
- Operates on compressed columnar chunks  

### âœ”ï¸ Metadata RAG is kept small  
You embed only:
- Table names  
- Column names  
- Column sample stats  

Even 5000 tables will produce tiny metadata.

### âœ”ï¸ FAISS Index handles millions of embeddings  
With:
- IVF  
- HNSW  
- PQ compression  

### âœ”ï¸ SQL Executor performs vectorized operations

### âœ”ï¸ LLM Agents do NOT see raw data  
Only:
- Schemas  
- Query context  
- Summaries  

### âœ”ï¸ Horizontal scaling with:
- Distributed FAISS (e.g., Milvus or Pinecone)  
- Partitioned Parquet  
- Multiple orchestrator workers  

---

## ğŸ” 10. Safety Layers

### Token Safety Guard  
- Reject large prompts  
- Reject queries returning too many rows  
- Toggle safety from config  

### SQL Safety  
- Prevents DDL/DML  
- Allows only SELECT  

### Flow Safety  
- Early rejection for out-of-domain queries  
- Controlled LLM usage  

---

## ğŸ“š 11. API Reference

### `POST /api/ask`
Natural language â†’ structured insight.

### `POST /api/sql`
Run raw SQL.

### `GET /api/health`
Version, provider, model.

---

## ğŸš¢ 12. Deployment (Docker + EC2 Ready)

### Build:
```
docker build -t maag .
```

### Run:
```
docker-compose up
```

Supports:
- FastAPI backend
- Gradio UI
- DuckDB in persistent volume
- Optional reverse proxy

---

## ğŸ§© 13. Future Enhancements

- Semantic SQL join graph  
- Multi-table join planner  
- Interactive dashboards  
- Streaming query results  
- User-level auth + sessions  
- LangGraph workflow UI  

---

## ğŸ¤ 14. Credits

Designed & implemented as part of an advanced agentic analytics assignment using:
- Python  
- DuckDB  
- FAISS  
- LangChain components  
- OpenAI + Gemini  
- FastAPI  
- Gradio  

---

## ğŸ–¥ï¸ 15. Technical Documentation & Presentation

[View Full MAAG Technical Architecture Presentation (PPT)](./MAAG_Docs/MAAG.pptx)


---

## ğŸ“¹ 16. FastAPI and Gradio UI âš™ï¸

The system flows from the Gradio UI/FastAPI layer down through the agent pipeline and DuckDB executor.

<p align="center">
  <img src="./MAAG_Docs/server_docs.png" alt="MAAG High-Level Architecture Diagram" width="700">
  <br>
  <i>FastAPI API's to access MAAG.</i>
</p>

<p align="center">
  <img src="./MAAG_Docs/UI-top.png" alt="MAAG High-Level Architecture Diagram" width="700">
  <br>
  <i>Gradio UI to access MAAG.</i>
</p>

<p align="center">
  <img src="./MAAG_Docs/UI-Bottom.png" alt="MAAG High-Level Architecture Diagram" width="700">
  <br>
  <i>Gradio UI to access MAAG.</i>
</p>


---

# ğŸš€ MAAG is now ready for production-grade evaluation!

